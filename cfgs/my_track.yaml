# obj_detect_checkpoint_file: models/mot17_crowdhuman_deformable_multi_frame/checkpoint_epoch_40.pth
obj_detect_checkpoint_file: training_results/BKTRIS_TRAINING/experiment_8_8_train_2/checkpoint_best_MOTA.pth
verbose: false
seed: 999
dataset_name: seq_1_val
data_root_dir: data
# output_dir: tracking_results/BKTRIS_TRAINING/experiment_8_8_track_2
output_dir: tracking_results/temp_9_8
# output_dir: results/BKTRIS_TRAINING/track_eval_7_8_22
interpolate: False
# if available load tracking results and only evaluate
load_results_dir: null

# dataset (look into src/datasets/tracking/factory.py)
# dataset_name: seq_0_val
# dataset_name: bktris/seq_0_val
# data_root_dir: data

# [False, 'debug', 'pretty']
# compile video with: `ffmpeg -f image2 -framerate 15 -i %06d.jpg -vcodec libx264 -y movie.mp4 -vf scale=320:-1`
write_images: debug
# Maps are only visualized if write_images is True
generate_attention_maps: False

# track, evaluate and write images only for a range of frames (in float fraction)
frame_range:
    start: 0.0
    end: 1.0

tracker_cfg:
    # [False, 'center_distance', 'min_iou_0_5']
    public_detections: False
    # score threshold for detection
    detection_obj_score_thresh: 0.3
    # score threshold for keeping the track alive
    track_obj_score_thresh: 0.3
    # NMS threshold for detection
    detection_nms_thresh: 0.4
    # NMS theshold while tracking
    track_nms_thresh: 0.4
    # number of consective steps a score has to be below track_obj_score_thresh for a track to be terminated
    steps_termination: 1
    # distance of previous frame for multi-frame attention
    prev_frame_dist: 1
    # How many timesteps inactive tracks are kept and cosidered for reid
    inactive_patience: 5
    # How similar do image and old track need to be to be considered the same person
    reid_sim_threshold: 0.0
    reid_sim_only: false
    reid_score_thresh: 0.4
    reid_greedy_matching: false
